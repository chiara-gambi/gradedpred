---
title: "Gambi, Jindal, Sharpe, Pickering, & Rabagliati (2019). The relation between preschoolers’ vocabulary development and their ability to predict and recognize words."
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    number_sections: true
---

# Cross-sectional Analyses

## The development of graded predictions {.tabset .tabset-fade}

### Set-up
```{r setup,warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
# load the data in
## NOTE: The data have been pre-processed to remove 295 trials (4.6%) 
## where children pointed or spoke before the sentence was over;
## Trials were children pointed to the incorrect picture are included (see Correct column)
al<-read.table("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase1/children_CORRECT.txt",header=T)

# load packages
library(doBy)
library(lme4)
library(ggplot2)
library(cowplot)
library(ggpubr)
library(ggthemes)
library(GGally)
library(reshape2)
library(dplyr)
library(bootstrap)
library(stringr)
library(lubridate)

# Function for matrix correlation plot
my_fn <- function(data, mapping, ...){
  p <- ggplot(data = data, mapping = mapping) + 
    geom_point() + 
    #geom_smooth(method=loess, fill="red", color="red", ...) +
    geom_smooth(method=lm, fill="blue", color="blue", ...)
  p
}

# Functions to compute 95% bootstrap CI's (adapted from Mike Frank's github)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}

# Create the trial selections for analyses in the prediction window.
## We discard trials for which no gaze data was recorded (due to track loss or looking away) for more than 40% of the duration of the time window
## Prediction window: from 1000ms before Noun Onset to 100ms after Noun Onset

## Mark fixations that did not overlap with the time window of interest as "NOHIT"; 
al$FIXPOSTDO<-as.character(al$AOIName)
al$FIXPOSTDO[(al$FixationStart<(al$TargetOnset-1000) & al$FixationEnd< (al$TargetOnset-1000))]<-"NOHIT"
al$FIXPOSTDO[(al$FixationStart>(al$TargetOnset+100)&al$FixationEnd>(al$TargetOnset+100))]<-"NOHIT"

## For fixations that only partially overlap with the time window of interest, compute the duration of the fix within the time window
al$DURPOSTDO<-al$FixationDuration
al$DURPOSTDO[al$FIXPOSTDO=="NOHIT"]<-NA
al$DURPOSTDO[is.na(al$DURPOSTDO)==F&al$FixationStart<(al$TargetOnset-1000)]<-al$DURPOSTDO[is.na(al$DURPOSTDO)==F&al$FixationStart<(al$TargetOnset-1000)]-(al$TargetOnset[is.na(al$DURPOSTDO)==F&al$FixationStart<(al$TargetOnset-1000)]-1000-al$FixationStart[is.na(al$DURPOSTDO)==F&al$FixationStart<(al$TargetOnset-1000)])
al$DURPOSTDO[is.na(al$DURPOSTDO)==F&al$FixationEnd>(al$TargetOnset+100)]<-al$DURPOSTDO[is.na(al$DURPOSTDO)==F&al$FixationEnd>(al$TargetOnset+100)]-(al$FixationEnd[is.na(al$DURPOSTDO)==F&al$FixationEnd>(al$TargetOnset+100)]-(al$TargetOnset[is.na(al$DURPOSTDO)==F&al$FixationEnd>(al$TargetOnset+100)]+100))
alD<-al[is.na(al$DURPOSTDO)==F,]

fixsumDT<-summaryBy(DURPOSTDO ~Participant + Trial + Bias + Named+ ItemF +TargetOnset+AGEYEAR,data=alD, FUN=sum, keep.names=T)
fixsumDT$Perc_Dur<-fixsumDT$DURPOSTDO*100/(1100)
fixsumDT$DiscardTrial<-0
fixsumDT$DiscardTrial[fixsumDT$Perc_Dur<40]<-1
fixsumDT$DiscardTrial[fixsumDT$DiscardTrial>1]<-1

## now average by subject and condition to obtain the proportion of discarded trials 
discardbySubj<-summaryBy(DiscardTrial ~ Participant + Bias + Named+AGEYEAR,data=fixsumDT, FUN=mean,keep.names=T)
#write.table(discardbySubj, "discarded_trials_prediction_children.txt")

## total number of trials contributing per subject and condition
fixsumDTbis<-fixsumDT[fixsumDT$DiscardTrial==0,]
## note that if a condition is missing for a subject in this summary it's because the subject contributed 0 trials to that condition after discarding track loss trials.
keptbySubj<-summaryBy(DiscardTrial ~ Participant + Bias +Named+AGEYEAR,data=fixsumDTbis, FUN=length,keep.names=T)
#write.table(keptbySubj,"valid_trials_prediction_children.txt")

```

### Graphs
```{r graphs}
## Figure 2 (main paper). Gaze patterns during the prediction window. Raw fixation proportions to the three pictures as a function of context and (A) age group (two year olds, three year olds, and four-to-five year olds) or (B) quartile of the raw vocabulary measure (1st quartile, interquartile range, 3rd quartile). (C) Time course of the empirical log odds of looking at the predictable (fine dashed line), unpredictable (coarser dashed line), and mildly predictable picture (solid line) while listening to predictive vs. neutral contexts. Error bars represent 95% bootstrap CI’s.

## Panels A and B plot average fixation proportion over time for each picture (A,B,C) in 50 ms time bins
## For the purprose of this analysis a fixation is counted as falling in a AOI in a given bin 
## if it is ongoing when the bin starts, or starts after the bin starts and ends before or after the bin ends, 
## or if it was ongoing when the bin ends. The variable FixLoc codes whether a given fixation was on picture A, B, or C; White space is coded as fourth category (Background)
al$A<-as.character(al$A)
al$B<-as.character(al$B)
al$C<-as.character(al$C)
##NOTE: "window" in Item 3 should be window2; "hair" in item 11 should be hair2 (to distinguish them from different instances of the same objects used in other items).
al$A[al$ItemF=="11"]<-"Hair2"
al$B[al$ItemF=="3"]<-"Window2"

al$FixLoc<-NA
for (i in 1:nrow(al)){
  if (al$AOIName[i]==tolower(gsub(" ","",al$A[i]))){al$FixLoc[i]<-"A"}
  if (al$AOIName[i]==tolower(gsub(" ","",al$B[i]))){al$FixLoc[i]<-"B"}
  if (al$AOIName[i]==tolower(gsub(" ","",al$C[i]))){al$FixLoc[i]<-"C"}
  if (al$AOIName[i]=="White Space"){al$FixLoc[i]<-"Background"}
}
alp<-al
for (i in (-20:2)){
  k<-paste(50*i,sep="")
  j=i-1
  alp$x<-alp$FixLoc
  alp$x[(alp$FixationStart<(alp$TargetOnset + 50*j) & alp$FixationEnd< (alp$TargetOnset + 50*j))|(alp$FixationStart>(alp$TargetOnset + 50*i) & alp$FixationEnd> (alp$TargetOnset + 50*i))]<-NA
  i=i+1
  alp$x<-as.factor(alp$x)
  names(alp)[names(alp)=="x"]<-k
}
## change to long format
names(alp)[75:97] # make sure you are selecting only time-varying columns
alp.l<-melt(alp,id.vars=names(alp)[1:74])
alp.l$AFIXBIN<-0
alp.l$BFIXBIN<-0
alp.l$CFIXBIN<-0
alp.l$BackgroundFIXBIN<-0
alp.l$AFIXBIN[is.na(alp.l$value)==F&alp.l$value=="A"]<-1
alp.l$BFIXBIN[is.na(alp.l$value)==F&alp.l$value=="B"]<-1
alp.l$CFIXBIN[is.na(alp.l$value)==F&alp.l$value=="C"]<-1
alp.l$BackgroundFIXBIN[is.na(alp.l$value)==F&alp.l$value=="Background"]<-1
alp.l$time<-as.numeric(as.character(alp.l$variable))

## discard irrelevant fixations
alp.lD<-alp.l[is.na(alp.l$DURPOSTDO)==F,]
fixsumbin<-summaryBy(AFIXBIN + BFIXBIN + CFIXBIN + BackgroundFIXBIN + DURPOSTDO ~ time + Participant + Trial + ItemF+ Bias+Block+TargetOnset+Age+BPVS+AGEYEAR, data=alp.lD, FUN = sum, keep.names=T, na.rm=T)
fixsumbin$AFIXBIN[fixsumbin$AFIXBIN>1]<-1
fixsumbin$BFIXBIN[fixsumbin$BFIXBIN>1]<-1
fixsumbin$CFIXBIN[fixsumbin$CFIXBIN>1]<-1
fixsumbin$BackgroundFIXBIN[fixsumbin$BackgroundFIXBIN>1]<-1
## apply %40 rejection criterion
fixsumbin$Perc_Dur<-fixsumbin$DURPOSTDO*100/(1100)
fixsumbin$DiscardTrial<-0
fixsumbin$DiscardTrial[fixsumbin$Perc_Dur<40]<-1
fixsumbin$DiscardTrial[fixsumbin$DiscardTrial>1]<-1

fixsumbin<-fixsumbin[fixsumbin$DiscardTrial==0,]
#write.table(fixsumbin,"children_pred_bytrial-cleaned.txt",row.names=F)

## Looks to A/B/C across the three Bias conditions, removing Background.
fixpropbinABC<-summaryBy(AFIXBIN + BFIXBIN + CFIXBIN + BackgroundFIXBIN ~ time + Participant + Bias+Age+BPVS+AGEYEAR, data=subset(fixsumbin,BackgroundFIXBIN==0), FUN = mean, keep.names=T, na.rm=T)
## turn into long format
names(fixpropbinABC)[1]<-"Time.ms"
names(fixpropbinABC)[3]<-"Context"
names(fixpropbinABC)[7]<-"FIXBIN.A"
names(fixpropbinABC)[8]<-"FIXBIN.B"
names(fixpropbinABC)[9]<-"FIXBIN.C"
fixpropbinABC<-fixpropbinABC[,-10]
fixpropbinABC_l<-reshape(fixpropbinABC,varying=names(fixpropbinABC)[7:9],direction="long")
names(fixpropbinABC_l)[7]<-"Picture"
levels(fixpropbinABC_l$Context)<-c("A-biasing","C-biasing","Neutral")

#Panel A (age)
fixpropbinABC_l.CI<-summaryBy(FIXBIN~Time.ms+Picture+Context+AGEYEAR,data=fixpropbinABC_l,FUN=c(mean, ci.high,ci.low))
fixpropbinABC_l.CI$AGEYEAR<-factor(fixpropbinABC_l.CI$AGEYEAR, levels=c("Two","Three","Four-Five"))
propABC_loess_pred_age2<-ggplot(fixpropbinABC_l.CI,aes(x=Time.ms,y=(FIXBIN.mean), color=Picture,linetype=Picture))+
  geom_line(stat = "identity", size = 1) + 
  geom_linerange(aes(ymin= (FIXBIN.mean - FIXBIN.ci.low), ymax= (FIXBIN.mean + FIXBIN.ci.high)), position = position_dodge(width=.9), size =0.5)+
  facet_grid(AGEYEAR~Context)+ylab("Fixation proportions")+theme(legend.position = "bottom")+ylim(.15,.55)+theme(axis.text.x = element_text(size=10))+
  scale_color_manual(values=c("#009E73","#D55E00","#CC79A7"))

# Panel B (Vocabulary)
fixpropbinABC_l$Voc2<-"1st quartile"
fixpropbinABC_l$Voc2[fixpropbinABC_l$BPVS>30]<-"Interquartile"
fixpropbinABC_l$Voc2[fixpropbinABC_l$BPVS>54]<-"3rd quartile"
fixpropbinABC_l$Voc2<-factor(fixpropbinABC_l$Voc2, levels=c("1st quartile","Interquartile","3rd quartile"))
fixpropbinABC_l.CI2<-summaryBy(FIXBIN~Time.ms+Picture+Context+Voc2,data=fixpropbinABC_l,FUN=c(mean, ci.high,ci.low))
propABC_loess_pred_voc2<-ggplot(fixpropbinABC_l.CI2,aes(x=Time.ms,y=(FIXBIN.mean), color=Picture,linetype=Picture))+geom_line(stat = "identity", size = 1) + geom_linerange(aes(ymin= (FIXBIN.mean - FIXBIN.ci.low), ymax= (FIXBIN.mean + FIXBIN.ci.high)), position = position_dodge(width=.9), size =0.5)+facet_grid(Voc2~Context)+ylab("Fixation proportions")+theme(legend.position = "bottom")+ylim(.15,.55)+theme(axis.text.x = element_text(size=10))+scale_color_manual(values=c("#009E73","#D55E00","#CC79A7"))

# Panel C
## Difference curves (by participants, with elog transform)
## Load in data
fixsumbin<-read.table("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase1/children_pred_bytrial-cleaned.txt",header=T)

## (Following Brock Ferguson example)
## http://brockferguson.com/tutorials/R-gca-workshop/tutorial4-growth-curve-analysis.html#orthogonal-polynomial-growth-curve-analysis
bySubj <- fixsumbin[fixsumbin$BackgroundFIXBIN==0,] %>%
  group_by(Participant,Bias,time) %>% # aggregate within time slices
  summarise(AFIXBIN.m = mean(AFIXBIN), BFIXBIN.m = mean(BFIXBIN), CFIXBIN.m = mean(CFIXBIN), yA = sum(AFIXBIN), yB = sum(BFIXBIN), yC = sum(CFIXBIN), N_A = length(AFIXBIN),N_B = length(BFIXBIN),N_C = length(CFIXBIN)) %>%
  mutate(elogA = log( (yA + .5) / (N_A - yA + .5) ), 
         elogB = log( (yB + .5) / (N_B - yB + .5) ),
         elogC = log( (yC + .5) / (N_C - yC + .5) )) %>%  # empirical logit
    ungroup()        
part.info<-summaryBy(time~Participant+AGEYEAR+Age+BPVS, data=fixsumbin,FUN=mean)
part.info<-part.info[,-5]
bySubj<-merge(bySubj,part.info,by=c("Participant"),sort=FALSE)
bySubj_tow<-as.data.frame(bySubj[,c(1:3,13:18)])
bySubj.w<-reshape(bySubj_tow,v.names=c("elogA","elogB","elogC"),timevar=c("Bias"),idvar=c("Participant","time","AGEYEAR","Age","BPVS"),direction="wide")
## compute differences
bySubj.w$A.CBA<-bySubj.w$elogA.CBA-bySubj.w$elogA.FLAT
bySubj.w$B.CBA<-bySubj.w$elogB.CBA-bySubj.w$elogB.FLAT
bySubj.w$C.CBA<-bySubj.w$elogC.CBA-bySubj.w$elogC.FLAT

bySubj.w$A.ABC<-bySubj.w$elogA.ABC-bySubj.w$elogA.FLAT
bySubj.w$B.ABC<-bySubj.w$elogB.ABC-bySubj.w$elogB.FLAT
bySubj.w$C.ABC<-bySubj.w$elogC.ABC-bySubj.w$elogC.FLAT

diff<-bySubj.w[,c(1:5,15:20)]
names(diff)[2]<-"Time.ms"
diff<-reshape(diff,varying=names(diff)[6:11],direction="long")
names(diff)[6]<-"Contrast"
names(diff)[7:9]<-c("Picture.A","Picture.B","Picture.C")
diff<-diff[,-10]
diff<-reshape(diff,varying=names(diff)[7:9],direction="long")

## collapsing across A and C
diff$PictureP<-"Unpredictable"
diff$PictureP[diff$time=="B"]<-"Mildly-predictable"
diff$PictureP[diff$time=="A"&diff$Contrast=="ABC"]<-"Predictable"
diff$PictureP[diff$time=="C"&diff$Contrast=="CBA"]<-"Predictable"
diff.meanCI.comb<-summaryBy(Picture~Time.ms+PictureP,data=diff, FUN=c(mean,ci.low,ci.high),keep.names=F,na.rm=T)
names(diff.meanCI.comb)[2]<-"Picture"
## This is the graph shown in Figure 2, panel C, main text.
elog_diff_CI_pred_comb<-ggplot(diff.meanCI.comb,aes(x=Time.ms,y=Picture.mean,linetype=Picture))+geom_line(stat = "identity", size = 1) + geom_linerange(aes(ymin= (Picture.mean - Picture.ci.low), ymax= (Picture.mean + Picture.ci.high)), position = position_dodge(width=.9), size =0.5)+ylab("Empirical logit Difference")+theme(legend.position = "bottom")
print(elog_diff_CI_pred_comb)

## Combine panels A, B, C of Figure 2, main text
raw_comb<-ggarrange(propABC_loess_pred_age2,propABC_loess_pred_voc2,ncol=1,labels=c("A", "B"),common.legend = T, legend="bottom")
all_comb<-ggarrange(raw_comb,elog_diff_CI_pred_comb,ncol=1,heights=c(2,1),labels=c("","C"))
print(all_comb)
ggsave("growthcurve.CI_pred_children_elog_raw.png", plot=all_comb, width=15, height=45, unit="cm", dpi=300, path=getwd())
dev.off()

## These graphs are shown in Figure S2, section 4.1 of the Supplement
## by age group (Panel A)
diff.meanCI.comb.A<-summaryBy(Picture~Time.ms+PictureP+AGEYEAR,data=diff, FUN=c(mean,ci.low,ci.high),keep.names=F,na.rm=T)
names(diff.meanCI.comb.A)[2]<-"Picture"
diff.meanCI.comb.A$AGEYEAR<-factor(diff.meanCI.comb.A$AGEYEAR, levels=c("Two","Three","Four-Five"))
elog_diff_CI_pred_comb.A<-ggplot(diff.meanCI.comb.A,aes(x=Time.ms,y=Picture.mean,linetype=Picture))+geom_line(stat = "identity", size = 1) + geom_linerange(aes(ymin= (Picture.mean - Picture.ci.low), ymax= (Picture.mean + Picture.ci.high)), position = position_dodge(width=.9), size =0.5)+facet_grid(~AGEYEAR)+ylab("Empirical logit Difference")+theme(legend.position = "bottom")
print(elog_diff_CI_pred_comb.A)
## by vocabulary size (Panel B)
diff.meanCI.comb.V<-diff
diff.meanCI.comb.V$Voc2<-"1st quartile"
diff.meanCI.comb.V$Voc2[diff.meanCI.comb.V$BPVS>30]<-"Interquartile"
diff.meanCI.comb.V$Voc2[diff.meanCI.comb.V$BPVS>54]<-"3rd quartile"
diff.meanCI.comb.V$Voc2<-factor(diff.meanCI.comb.V$Voc2, levels=c("1st quartile","Interquartile","3rd quartile"))
diff.meanCI.comb.V<-summaryBy(Picture~Time.ms+PictureP+Voc2,data=diff.meanCI.comb.V, FUN=c(mean,ci.low,ci.high),keep.names=F,na.rm=T)
names(diff.meanCI.comb.V)[2]<-"Picture"
elog_diff_CI_pred_comb.V<-ggplot(diff.meanCI.comb.V,aes(x=Time.ms,y=Picture.mean,linetype=Picture))+geom_line(stat = "identity", size = 1) + geom_linerange(aes(ymin= (Picture.mean - Picture.ci.low), ymax= (Picture.mean + Picture.ci.high)), position = position_dodge(width=.9), size =0.5)+facet_grid(~Voc2)+ylab("Empirical logit Difference")+theme(legend.position = "bottom")
print(elog_diff_CI_pred_comb.V)

## combine panels A, B of Figure S2, section 4.1, Supplement
diffAV<-ggarrange(elog_diff_CI_pred_comb.A,elog_diff_CI_pred_comb.V,ncol=1,labels=c("A", "B"),common.legend = T,legend="bottom")
ggsave("growthcurve.CI_pred_children_elog_raw_agevoc.png", plot=diffAV, width=30, height=15, unit="cm", dpi=300, path=getwd())
dev.off()
```

### Growth Curve Analyses
```{r analyses}
## By-participant analyses, collapsing across A-biasing and C-biasing contexts (main text and section 4.4, Supplement)
gca<-diff
names(gca)[2]<-"time"
names(gca)[8]<-"Elog"
names(gca)[7]<-"Picture"
gca$PictureP<-"UnPred"
gca$PictureP[gca$Picture=="B"]<-"Mildly Pred"
gca$PictureP[gca$Picture=="A"&gca$Contrast=="ABC"]<-"Pred"
gca$PictureP[gca$Picture=="C"&gca$Contrast=="CBA"]<-"Pred"
t<-poly(unique(gca$time),2)
time<-as.vector(unique(gca$time))
t<-cbind(t,time)
t<-as.data.frame(t)
gca<-gca[order(gca$time),]
gca$t1<-NA
gca$t2<-NA
for (i in (1:nrow(gca))){
  gca$t1[i]<-t[t$time==gca$time[i],1] 
  gca$t2[i]<-t[t$time==gca$time[i],2] 
}
gca$PictureP<-as.factor(gca$PictureP)
gca$PictureP<-relevel(gca$PictureP,ref="Mildly Pred")
gca$Pred<-ifelse(gca$PictureP=="Pred", 1,0)
gca$Unpred<-ifelse(gca$PictureP=="UnPred", 1,0)
gca$AC<-scale(gca$Age,T,F)
gca$VC<-scale(gca$BPVS,T,F)

mdiffPredUnpred.AV<-lmer(Elog~1+(t1+t2)*(Pred+Unpred)*(AC+VC)+(1+t1+t2|Participant)+(1+t1+t2|Participant:Pred)+(1+t1+t2|Participant:Unpred),data=gca,REML=F,control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(mdiffPredUnpred.AV)
confint(mdiffPredUnpred.AV, method="Wald")

## fit separate models with age or vocabulary as covariate
## age
mdiffPredUnpred.A<-lmer(Elog~1+(t1+t2)*(Pred+Unpred)*(AC)+(1+t1+t2|Participant)+(1+t1+t2|Participant:Pred)+(1+t1+t2|Participant:Unpred),data=gca,REML=F,control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(mdiffPredUnpred.A)

mdiffPredUnpred.V<-lmer(Elog~1+(t1+t2)*(Pred+Unpred)*(VC)+(1+t1+t2|Participant)+(1+t1+t2|Participant:Pred)+(1+t1+t2|Participant:Unpred),data=gca,REML=F,control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(mdiffPredUnpred.V)

## Model comparison
# compare age only model to age+voc model
anova(mdiffPredUnpred.A,mdiffPredUnpred.AV)#17.463      9    0.04194 *
#compare voc only model to age+voc model
anova(mdiffPredUnpred.V,mdiffPredUnpred.AV)#14.808      9    0.09635 .

# Test separately adding interactions between Voc and Pred and between Voc and Unpred
mdiffPredUnpred.AVB<-lmer(Elog~1+(t1+t2)*(Pred+Unpred)*(AC)+(t1+t2)*(VC)+(1+t1+t2|Participant)+(1+t1+t2|Participant:Pred)+(1+t1+t2|Participant:Unpred),data=gca,REML=F,control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
mdiffPredUnpred.AVP<-lmer(Elog~1+(t1+t2)*(Pred+Unpred)*(AC)+(t1+t2)*(Pred)*(VC)+(1+t1+t2|Participant)+(1+t1+t2|Participant:Pred)+(1+t1+t2|Participant:Unpred),data=gca,REML=F,control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
# adding interactions between Voc and the Pred-MildyPred contrast
anova(mdiffPredUnpred.AVB,mdiffPredUnpred.AVP)#5.1359      3     0.1621
# adding interactions between Voc and the Unpred-MildlyPred contrast
anova(mdiffPredUnpred.AVP,mdiffPredUnpred.AV)#10.494      3     0.0148 *


## By-participant analyses, separately for A-biasing and C-biasing contexts (section 4.2, Supplement)
gca<-as.data.frame(diff)
names(gca)[2]<-"time"
names(gca)[8]<-"Elog"
names(gca)[7]<-"Picture"
t<-poly(unique(gca$time),2)
time<-as.vector(unique(gca$time))
t<-cbind(t,time)
t<-as.data.frame(t)
gca<-gca[order(gca$time),]
gca$t1<-NA
gca$t2<-NA
for (i in (1:nrow(gca))){
  gca$t1[i]<-t[t$time==gca$time[i],1] 
  gca$t2[i]<-t[t$time==gca$time[i],2] 
}
gca$Picture<-as.factor(gca$Picture)
gca$Picture<-relevel(gca$Picture,ref="B")
gca$BD1<-ifelse(gca$Picture=="A", 1,0)
gca$BD2<-ifelse(gca$Picture=="C", 1,0)
gca$AC<-scale(gca$Age,T,F)
gca$VC<-scale(gca$BPVS,T,F)
gca$Participant<-as.factor(gca$Participant)
gca<-gca[,-9]

## C-biasing model
mdiffCBA.AV<-lmer(Elog~1+(t1+t2)*(BD1+BD2)*(AC+VC)+t1*(1+t1+t2|Participant)+(1+t1+t2|Participant:BD1)+(1+t1+t2|Participant:BD2),data=subset(gca,Contrast=="CBA-FLAT"),REML=F)
summary(mdiffCBA.AV)
confint(mdiffCBA.AV, method="Wald")
## A-biasing model
mdiffABC.AV<-lmer(Elog~1+(t1+t2)*(BD1+BD2)*(AC+VC)+(1+t1+t2|Participant)+(1+t1+t2|Participant:BD1)+(1+t1+t2|Participant:BD2),data=subset(gca,Contrast=="ABC-FLAT"),REML=F)
summary(mdiffABC.AV)
confint(mdiffABC.AV,method="Wald")
 
## By-item analyses, collapsing across A-biasing and C-biasing contexts (section 4.3, Supplement)
byItem <- fixsumbin[fixsumbin$BackgroundFIXBIN==0,] %>%
  group_by(ItemF,Bias,time) %>% # aggregate within time slices
  summarise(AFIXBIN.m = mean(AFIXBIN), BFIXBIN.m = mean(BFIXBIN), CFIXBIN.m = mean(CFIXBIN), yA = sum(AFIXBIN), yB = sum(BFIXBIN), yC = sum(CFIXBIN), N_A = length(AFIXBIN),N_B = length(BFIXBIN),N_C = length(CFIXBIN)) %>%
  mutate(elogA = log( (yA + .5) / (N_A - yA + .5) ),
         elogB = log( (yB + .5) / (N_B - yB + .5) ),
         elogC = log( (yC + .5) / (N_C - yC + .5) )) %>%  # empirical logit
  ungroup()
byItem_tow<-as.data.frame(byItem[,c(1:3,13:15)])
byItem.w<-reshape(byItem_tow,v.names=c("elogA","elogB","elogC"),timevar=c("Bias"),idvar=c("ItemF","time"),direction="wide")
## compute differences
byItem.w$A.CBA<-byItem.w$elogA.CBA-byItem.w$elogA.FLAT
byItem.w$B.CBA<-byItem.w$elogB.CBA-byItem.w$elogB.FLAT
byItem.w$C.CBA<-byItem.w$elogC.CBA-byItem.w$elogC.FLAT

byItem.w$A.ABC<-byItem.w$elogA.ABC-byItem.w$elogA.FLAT
byItem.w$B.ABC<-byItem.w$elogB.ABC-byItem.w$elogB.FLAT
byItem.w$C.ABC<-byItem.w$elogC.ABC-byItem.w$elogC.FLAT

diff.I<-byItem.w[,c(1:2,12:17)]
names(diff.I)[2]<-"Time.ms"

##turn to long format
diff.I<-reshape(diff.I,varying=names(diff.I)[3:8],direction="long")
names(diff.I)[3]<-"Contrast"
names(diff.I)[4:6]<-c("Picture.A","Picture.B","Picture.C")
diff.I<-diff.I[,-7]
diff.I<-reshape(diff.I,varying=names(diff)[4:6],direction="long")

#analyze
gca<-diff.I
names(gca)[2]<-"time"
names(gca)[5]<-"Elog"
names(gca)[4]<-"Picture"
gca$PictureP<-"UnPred"
gca$PictureP[gca$Picture=="B"]<-"Mildly Pred"
gca$PictureP[gca$Picture=="A"&gca$Contrast=="ABC"]<-"Pred"
gca$PictureP[gca$Picture=="C"&gca$Contrast=="CBA"]<-"Pred"
t<-poly(unique(gca$time),2)
time<-as.vector(unique(gca$time))
t<-cbind(t,time)
t<-as.data.frame(t)
gca<-gca[order(gca$time),]
gca$t1<-NA
gca$t2<-NA
for (i in (1:nrow(gca))){
  gca$t1[i]<-t[t$time==gca$time[i],1] 
  gca$t2[i]<-t[t$time==gca$time[i],2] 
}
gca$PictureP<-as.factor(gca$PictureP)
gca$PictureP<-relevel(gca$PictureP,ref="Mildly Pred")
gca$Pred<-ifelse(gca$PictureP=="Pred", 1,0)
gca$Unpred<-ifelse(gca$PictureP=="UnPred", 1,0)

mdiffPredUnpred.I<-lmer(Elog~1+(t1+t2)*(Pred+Unpred)+(1+t1+t2|ItemF)+(1+t1+t2|ItemF:Pred)+(1+t1+t2|ItemF:Unpred),data=gca,REML=F)
summary(mdiffPredUnpred.I)
confint(mdiffPredUnpred.I, method="Wald")
```

### Relation between Prediction skill, vocabulary size, and age
```{r correlations}
## Define the Prediction skill measure
## Average raw fixation proportions across the SHORT prediction window (-300ms to +100ms = 400ms duration)
spw<-subset(fixsumbin,BackgroundFIXBIN==0)
spw<-subset(spw,time>=-300)
spwa<-summaryBy(AFIXBIN + BFIXBIN + CFIXBIN ~ Participant + Trial + ItemF+ Bias+Block+TargetOnset+Age+BPVS+AGEYEAR, data=spw, FUN = mean, keep.names=T, na.rm=T)
spwa.subj<-summaryBy(AFIXBIN + BFIXBIN + CFIXBIN~Bias+Participant,data=spwa,FUN=mean, keep.names = T)
spwa.subj.w<-reshape(spwa.subj,v.names=c("AFIXBIN","BFIXBIN","CFIXBIN"),timevar=c("Bias"),idvar=c("Participant"),direction="wide")
## compute differences
spwa.subj.w$A.CBA<-spwa.subj.w$AFIXBIN.CBA-spwa.subj.w$AFIXBIN.FLAT
spwa.subj.w$B.CBA<-spwa.subj.w$BFIXBIN.CBA-spwa.subj.w$BFIXBIN.FLAT
spwa.subj.w$C.CBA<-spwa.subj.w$CFIXBIN.CBA-spwa.subj.w$CFIXBIN.FLAT

spwa.subj.w$A.ABC<-spwa.subj.w$AFIXBIN.ABC-spwa.subj.w$AFIXBIN.FLAT
spwa.subj.w$B.ABC<-spwa.subj.w$BFIXBIN.ABC-spwa.subj.w$BFIXBIN.FLAT
spwa.subj.w$C.ABC<-spwa.subj.w$CFIXBIN.ABC-spwa.subj.w$CFIXBIN.FLAT

##turn to long format
raw.diff<-reshape(spwa.subj.w,varying=names(spwa.subj.w)[11:16],direction="long")
raw.diff<-raw.diff[,c(1,11:14)]
names(raw.diff)[2:5]<-c("Contrast","Picture.A","Picture.B","Picture.C")
raw.diff<-reshape(raw.diff,varying=names(raw.diff)[3:5],direction="long")
names(raw.diff)[3]<-"Picture"
names(raw.diff)[4]<-"Prop"
raw.diff$PictureP<-"MildPred"
raw.diff$PictureP[raw.diff$Picture=="A"&raw.diff$Contrast=="ABC"]<-"Pred"
raw.diff$PictureP[raw.diff$Picture=="C"&raw.diff$Contrast=="CBA"]<-"Pred"
raw.diff$PictureP[raw.diff$Picture=="A"&raw.diff$Contrast=="CBA"]<-"UnPred"
raw.diff$PictureP[raw.diff$Picture=="C"&raw.diff$Contrast=="ABC"]<-"UnPred"
raw.diff<-summaryBy(Prop~PictureP+Participant,data=raw.diff,FUN=mean,keep.names=T)
raw.diff.w<-reshape(raw.diff,v.names=c("Prop"),idvar="Participant",timevar="PictureP",direction="wide")
raw.diff.w$rawPred<-raw.diff.w$Prop.Pred-raw.diff.w$Prop.MildPred
raw.diff.w$rawUnpred<-raw.diff.w$Prop.UnPred-raw.diff.w$Prop.MildPred

#save to file
#write.table(raw.diff.w[,c("Participant","rawPred","rawUnpred")],"rawshort_predindeces.txt",row.names = F)
## NOTE: rawPred is the preference for predictable over mildly predictable picture;
## rawUnpred is the dispreference for unpredictable compared to mildly predictable pictures

## Compute the combined graded prediction measure == rawPred - rawUnpred
raw<-read.table("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase1/rawshort_predindeces.txt",header=T)
## load participant info
part_info<-read.csv("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase2/part_info.csv",header=T,sep=",")
names(part_info)[14]<-"Participant"
all<-merge(part_info,raw,by=c("Participant"))

## Composite prediction index
all$PrecC_raw<-all$rawPred -all$rawUnpred

## Correlations
cor.test(all$rawPred, all$Age) #0.1930198 , t = 2.871, df = 213, p-value = 0.004504
cor.test(all$rawPred, all$BPVS) #0.214173, t = 3.2, df = 213, p-value = 0.001584
cor.test(all$rawUnpred, all$Age) #-0.06369757, t = -0.93153, df = 213, p-value = 0.3526
cor.test(all$rawUnpred, all$BPVS) #-0.01097391, t = -0.16017, df = 213, p-value = 0.8729
cor.test(all$PrecC_raw, all$Age) #0.368942, t = 5.7932, df = 213, p-value = 2.459e-08
cor.test(all$PrecC_raw, all$BPVS) #0.3257412 , t = 5.0283, df = 213, p-value = 1.049e-06

## Model comparison
mPrecC_raw1<-lm(PrecC_raw~1+Age,data=all)
mPrecC_raw2<-lm(PrecC_raw~1+Age+scale(BPVS),data=all)
anova(mPrecC_raw1,mPrecC_raw2)

## Graphs
## Figure 4A, main text
pred_raw_allc<-ggplot(all,aes(PrecC_raw,BPVS))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Size (raw BPVS score)")+xlab("Graded Prediction Measure (Prediction Skill)")
print(pred_raw_allc)

## Figure S3, section 4.5, Supplement
pred_raw_prefc<-ggplot(all,aes(rawPred,BPVS))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Size (raw BPVS score)")+xlab("Looks to Predictable - Mildly predictable pictures")
print(pred_raw_prefc)
pred_raw_disprefc<-ggplot(all,aes(rawUnpred,BPVS))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Size (raw BPVS score)")+xlab("Looks to Unpredictable - Mildly predictable pictures")
print(pred_raw_disprefc)
pred_pred_dispref_raw_allc<-ggarrange(pred_raw_prefc,pred_raw_disprefc,labels = c("A","B"), nrow=1)
ggsave("pred_pred_dispref_raw_all_crosssect.png", plot=pred_pred_dispref_raw_allc, width=45, height=15, unit="cm", dpi=300, path=getwd())
```


## Developmental change in revision skills {.tabset .tabset-fade}

### Setup
```{r setup rev}
## Fixation proportions
alr<-al
# The recognition window spans from Noun Onset + 100 to TotDur+1000
mean(time$TotDur-time$TargetOnset)*1000 # average duration of final word
alr$FIXATONSET<-as.character(alr$FixLoc)
alr$FIXATONSET[(alr$FixationStart<alr$TargetOnset&alr$FixationEnd<alr$TargetOnset)]<-"NOHIT"
alr$FIXATONSET[(alr$FixationStart>(alr$TargetOnset+100)&alr$FixationEnd>(alr$TargetOnset+100))]<-"NOHIT"
## Now create variable that codes whether FIXATONSET==B
alr$DISCARDBONSET<-0
alr$DISCARDBONSET[alr$FIXATONSET=="B"]<-1
## Now create variable that codes whether FIXATONSET==A
alr$DISCARDAONSET<-0
alr$DISCARDAONSET[alr$FIXATONSET=="A"]<-1
## Now create variable that codes whether FIXATONSET==C
alr$DISCARDCONSET<-0
alr$DISCARDCONSET[alr$FIXATONSET=="C"]<-1
for (i in (2:33)){
  k<-paste(50*i,sep="")
  j=i-1
  alr$x<-alr$FixLoc
  alr$x[(alr$FixationStart<(alr$TargetOnset + 50*j) & alr$FixationEnd< (alr$TargetOnset + 50*j))|(alr$FixationStart>(alr$TargetOnset + 50*i) & alr$FixationEnd> (alr$TargetOnset + 50*i))]<-NA
  i=i+1
  alr$x<-as.factor(alr$x)
  names(alr)[names(alr)=="x"]<-k
}
#change to long format
names(alr)[79:110]
alr.l<-melt(alr,id.vars=names(alr)[1:78])
alr.l$AFIXBIN<-0
alr.l$BFIXBIN<-0
alr.l$CFIXBIN<-0
alr.l$BackgroundFIXBIN<-0
alr.l$AFIXBIN[is.na(alr.l$value)==F&alr.l$value=="A"]<-1
alr.l$BFIXBIN[is.na(alr.l$value)==F&alr.l$value=="B"]<-1
alr.l$CFIXBIN[is.na(alr.l$value)==F&alr.l$value=="C"]<-1
alr.l$BackgroundFIXBIN[is.na(alr.l$value)==F&alr.l$value=="Background"]<-1
alr.l$time<-as.numeric(as.character(alr.l$variable))
alr.lD<-alr.l[is.na(alr.l$DURPOSTDO2)==F,]

fixsumbin2<-summaryBy(AFIXBIN + BFIXBIN + CFIXBIN + BackgroundFIXBIN + DURPOSTDO2+DISCARDBONSET+DISCARDAONSET+DISCARDCONSET ~ time + Participant + Trial + ItemF+ Named+Bias+Block+TargetOnset+TotDur+Age+BPVS+AGEYEAR, data=alr.lD, FUN = sum, keep.names=T, na.rm=T)
fixsumbin2$AFIXBIN[fixsumbin2$AFIXBIN>1]<-1
fixsumbin2$BFIXBIN[fixsumbin2$BFIXBIN>1]<-1
fixsumbin2$CFIXBIN[fixsumbin2$CFIXBIN>1]<-1
fixsumbin2$BackgroundFIXBIN[fixsumbin2$BackgroundFIXBIN>1]<-1

## apply %40 rejection criterion
fixsumbin2$Perc_Dur<-fixsumbin2$DURPOSTDO2*100/(fixsumbin2$TotDur+1000-(fixsumbin2$TargetOnset+100))
fixsumbin2$DiscardTrial<-0
fixsumbin2$DiscardTrial[fixsumbin2$Perc_Dur<40]<-1
fixsumbin2$DiscardTrial[fixsumbin2$DiscardTrial>1]<-1
fixsumbin2<-fixsumbin2[fixsumbin2$DiscardTrial==0,]
#write.table(fixsumbin2,"children_rec_bytrial-cleaned.txt",row.names=F)

fixsumbin2<-read.table("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase1/children_rec_bytrial-cleaned.txt",header=T)

###now discard trials were participants were looking at B at Onset (i.e DISSCARDBONSET>=1)
fixsumbin3<-fixsumbin2[fixsumbin2$DISCARDBONSET==0,]
#write.table(fixsumbin3,"children_rec_bytrial-cleaned_noBonset.txt",row.names=F)

## Time to first fixation
# Fixations that are not relevant to the recognition window (DURPOSTDO2==NA) must be discarded
alr.D<-alr[is.na(alr$DURPOSTDO2)==F,]
# We have already defined variables that code whether a given AOI was fixated at NounOnset+100 (DISCARDBONSET, etc.)
# We also have a variable that codes which AOI the fixation was to (FixLoc)

#This selects the first Fix for each trial and each FixLoc, and codes all the useful information with it
tff.rs<-summaryBy(FixationStart ~ FixLoc+Participant + Trial + ItemF+ Named+Bias+Block+TargetOnset+TotDur+Age+BPVS+AGEYEAR, data=alr.D, FUN = min, keep.names=T, na.rm=T)

#Separately, we need to get Trial-specific information
trial.info<-summaryBy(DURPOSTDO2+DISCARDBONSET+DISCARDAONSET+DISCARDCONSET~Participant + Trial,data=alr.D, FUN = sum, keep.names=T, na.rm=T )

#merge the two files
tff.rs.m<-merge(tff.rs,trial.info,by=c("Participant","Trial"))

#now we need to apply the rejection criterion
## apply %40 rejection criterion
tff.rs.m$Perc_Dur<-tff.rs.m$DURPOSTDO2*100/(tff.rs.m$TotDur+1000-(tff.rs.m$TargetOnset+100))
tff.rs.m$DiscardTrial<-0
tff.rs.m$DiscardTrial[tff.rs.m$Perc_Dur<40]<-1
tff.rs.m$DiscardTrial[tff.rs.m$DiscardTrial>1]<-1
tff.rs.m<-tff.rs.m[tff.rs.m$DiscardTrial==0,]

#and discard fixations to the background (FixLoc == Background)
tff.rs.m<-tff.rs.m[tff.rs.m$FixLoc!="Background",]

#select only trial in which B was the named picture AND were in Block 1
tff.rs.m.B<-tff.rs.m[tff.rs.m$Named=="B"&tff.rs.m$Block=="First",]

#discard trials with looks to the Target at Onset+100
tff.rs.m.B<-tff.rs.m.B[tff.rs.m.B$DISCARDBONSET==0,]

# select only fixations to B
tff.rs.m.B<-tff.rs.m.B[tff.rs.m.B$FixLoc=="B",]#1227

# exclude cases in which target was not fixated before the end of the Recognition window (TotDurt+1000)
tff.rs.m.B<-tff.rs.m.B[tff.rs.m.B$FixationStart<tff.rs.m.B$TotDur+1000,] # no such cases

# get Fixation Onset relative to Target Noun Onset
tff.rs.m.B$FixStartRel<-tff.rs.m.B$FixationStart-tff.rs.m.B$TargetOnset
summary(tff.rs.m.B$FixStartRel)

# check number of trials entered in the biasing vs. neutral condition is roughly balanced
tff.rs.m.B$count<-1
tff.rs.m.B.bypart<-summaryBy(count~Context+Participant,data=tff.rs.m.B,FUN=sum)
tff.rs.m.B.mean<-summaryBy(count.sum~Context,data=tff.rs.m.B.bypart,FUN=mean)
tff.rs.m.B.mean

tff.rs.m.B.median<-summaryBy(count.sum~Context,data=tff.rs.m.B.bypart,FUN=median)
tff.rs.m.B.median
```

### Graph

```{r graph rev}
## Fixation proportions
fixpropbin3<-summaryBy(AFIXBIN + BFIXBIN + CFIXBIN + BackgroundFIXBIN  ~ time + Participant + Named+Bias + Block+AGEYEAR+Age+BPVS, data=subset(fixsumbin3,BackgroundFIXBIN==0), FUN = mean, keep.names=T, na.rm=T)
## Looks to B when it is less expected (combining A/C-biasing) vs. when it is just as likely as other options
fixpropbinB_pred2<-fixpropbin3[fixpropbin3$Named=="B",]
fixpropbinB_pred2$Context<-"Biasing"
fixpropbinB_pred2$Context[fixpropbinB_pred2$Bias=="FLAT"]<-"Neutral"
fixpropbinB_pred2.CI<-summaryBy(BFIXBIN~time+Context+Participant+AGEYEAR+BPVS,data=fixpropbinB_pred2,FUN=mean,keep.names=T)
fixpropbinB_pred2.CI2<-fixpropbinB_pred2.CI
fixpropbinB_pred2.CI2$Voc2<-"1st quartile"
fixpropbinB_pred2.CI2$Voc2[fixpropbinB_pred2.CI2$BPVS>30]<-"Interquartile"
fixpropbinB_pred2.CI2$Voc2[fixpropbinB_pred2.CI2$BPVS>54]<-"3rd quartile"
fixpropbinB_pred2.CI<-summaryBy(BFIXBIN~time+Context+AGEYEAR,data=fixpropbinB_pred2.CI,FUN=c(mean,ci.low,ci.high),keep.names=T)
fixpropbinB_pred2.CI2<-summaryBy(BFIXBIN~time+Context+Voc2,data=fixpropbinB_pred2.CI2,FUN=c(mean,ci.low,ci.high),keep.names=T)
fixpropbinB_pred2.CI$AGEYEAR<-factor(fixpropbinB_pred2.CI$AGEYEAR,levels=c("Two","Three","Four-Five"))
fixpropbinB_pred2.CI2$Voc2<-factor(fixpropbinB_pred2.CI2$Voc2,levels=c("1st quartile","Interquartile","3rd quartile"))

# Age: Figure 3, Panel A, main text
rec_cost_CI_comb_age<-ggplot(fixpropbinB_pred2.CI,aes(x=time,y=BFIXBIN.mean,shape=Context, colour=Context))+
  geom_point(stat = "identity", size = 2)+ geom_line()+
  geom_linerange(aes(ymin= (BFIXBIN.mean - BFIXBIN.ci.low), ymax= (BFIXBIN.mean + BFIXBIN.ci.high)), position = position_dodge(width=.9), size =0.5) +
  ylim(c(0,1))+ylab("Proportion of Looks to Mildly Pred Pictures")+xlab("Time.ms")+theme(legend.position = "bottom")+
  facet_grid(rows=vars(AGEYEAR))+scale_color_manual(values=c("black","#E69F00"))

# Vocabulary: Figure 3, Panel B, main text
rec_cost_CI_comb_voc<-ggplot(fixpropbinB_pred2.CI2,aes(x=time,y=BFIXBIN.mean,shape=Context, colour=Context))+
  geom_point(stat = "identity", size = 2)+ geom_line()+
  geom_linerange(aes(ymin= (BFIXBIN.mean - BFIXBIN.ci.low), ymax= (BFIXBIN.mean + BFIXBIN.ci.high)), position = position_dodge(width=.9), size =0.5) +
  ylim(c(0,1))+ylab("Proportion of Looks to Mildly Pred Pictures")+xlab("Time.ms")+theme(legend.position = "bottom")+
  facet_grid(rows=vars(Voc2))+scale_color_manual(values=c("black","#E69F00"))

#combine panel A and B
rec_prop_comb<-ggarrange(rec_cost_CI_comb_age,rec_cost_CI_comb_voc,labels=c("A", "B"),common.legend = T, legend="bottom")

# Time to first fixation (Panel C)
tff.rs.m.B.CI<-summaryBy(FixStartRel~Participant+Context,data=tff.rs.m.B,FUN=c(mean), keep.names=T)
tff.rs.m.B.CI<-summaryBy(FixStartRel~Context,data=tff.rs.m.B,FUN=c(mean,ci.low,ci.high))
tff.barplot<-ggplot(tff.rs.m.B.CI,aes(y=FixStartRel.mean,x=Context,shape=Context, col=Context))+geom_pointrange(aes(y=FixStartRel.mean,ymin=FixStartRel.mean-FixStartRel.ci.low,ymax=FixStartRel.mean+FixStartRel.ci.high),size=2)+ylab("Time to first fixation (ms)")+theme(legend.position = "none")+scale_color_colorblind(2)                        

# Combine panels A, B, C 
rec_cost_all<-ggarrange(rec_prop_comb,tff.barplot,ncol=2,widths = c(2,1),labels=c("","C"))
print(rec_cost_all)
ggsave("CI_reccost_children_prop_tff.png", plot=rec_cost_all, width=45, height=15, unit="cm", dpi=300, path=getwd())
```

### Analysis
```{r rev analysis}
## The cost of disconfirmed predictions
# get some means
tff.rs.m.B$Context<-"Biasing"
tff.rs.m.B$Context[tff.rs.m.B$Bias=="FLAT"]<-"Neutral"
summaryBy(FixStartRel~Context,data=tff.rs.m.B,FUN=mean)

#model (Table S6, Section 5, Supplement)
tff.rs.m.B$PC<-ifelse(tff.rs.m.B$Context=="Neutral",.5,-.5)
tff.rs.m.B$PCC<-scale(tff.rs.m.B$PC,T,F)
tff.rs.m.B$AC<-scale(tff.rs.m.B$Age,T,F)
tff.rs.m.B$VC<-scale(tff.rs.m.B$BPVS,T,F)
ttf.lmer.reccost.AV.sf<-lmer(FixStartRel~1+PCC*(AC+VC)+(1+PCC||Participant)+(1+PCC||ItemF),data= tff.rs.m.B,REML=F)
# singular fit
# the participant random slope is estimated to be zero, so remove
ttf.lmer.reccost.AV<-lmer(FixStartRel~1+PCC*(AC+VC)+(1|Participant)+(1+PCC||ItemF),data= tff.rs.m.B,REML=F)
summary(ttf.lmer.reccost.AV)
confint(ttf.lmer.reccost.AV, method="Wald")

# fit separate models for Age (Table S7, Section 5, Supplement)
ttf.lmer.reccost.A<-lmer(FixStartRel~1+PCC*(AC)+(1|Participant)+(1+PCC||ItemF),data= tff.rs.m.B,REML=F)
summary(ttf.lmer.reccost.A)
confint(ttf.lmer.reccost.A, method="Wald")
# and vocabulary (Table S8, Section 5, Supplement)
ttf.lmer.reccost.V<-lmer(FixStartRel~1+PCC*(VC)+(1|Participant)+(1+PCC||ItemF),data= tff.rs.m.B,REML=F)
summary(ttf.lmer.reccost.V)
confint(ttf.lmer.reccost.V, method="Wald")

#compare AV model to A only model
anova(ttf.lmer.reccost.AV,ttf.lmer.reccost.A)#3.2415      2     0.1977
anova(ttf.lmer.reccost.AV,ttf.lmer.reccost.V)#1.045      2      0.593
```

### Relation between revision skill, vocabulary size and age
```{r rev correlations}
# Compute the revision skill measure (following Reuter et al., 2019, Dev Psych)
# Proportion of looks to B pictures when B was the named picture, and the context was Predictive (A-biasing or C-biasing), regardless of initial looks
# Still excluding looks to Background
# Averaged across the whole recognition window
fixpropbinR<-summaryBy(BFIXBIN  ~ Participant + Named+Bias, data=subset(fixsumbin2,BackgroundFIXBIN==0), FUN = mean, keep.names=T, na.rm=T)
fixpropbinR<-fixpropbinR[fixpropbinR$Named=="B",]
# to wide format
fixpropbinR.w<-reshape(fixpropbinR,v.names="BFIXBIN",timevar="Bias",idvar="Participant",direction="wide")
reviseReuter <- data.frame(Participant = fixpropbinR.w$Participant, RevR= rowMeans(fixpropbinR.w[,c("BFIXBIN.ABC","BFIXBIN.CBA")]))

predict_revise_R<-merge(predictReuter,reviseReuter,by="Participant")
predict_revise_R$predrevR<-predict_revise_R$RevR-predict_revise_R$PredR
# save to file
#write.table(predict_revise_R,"predict_revised_Reuter_Index.txt",row.names=F)

## Correlations
predict_revise<-read.table("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase1/predict_revised_Reuter_Index.txt",header=T)
all<-merge(all,predict_revise,by=c("Participant"))

cor.test(all$predrevR, all$Age) #0.4270497, t = 6.8603, df = 211, p-value = 7.495e-11
cor.test(all$predrevR, all$BPVS) #0.4936846 t = 8.2461, df = 211, p-value = 1.74e-14

## Model comparison
mpredrevR1<-lm(predrevR~1+Age,data=all)
mpredrevR2<-lm(predrevR~1+Age+scale(BPVS),data=all)
anova(mpredrevR1,mpredrevR2)

## Graph (Figure 4B, main text)
predrev_raw_allc<-ggplot(all,aes(predrevR,BPVS))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Size (raw BPVS score)")+xlab("Predict-and-Redirect Measure (Revision Skill)")
```

## Developmental change in processing speed {.tabset .tabset-fade}

### Setup
```{r setup proc_speed}
alr.D<-alr[is.na(alr$DURPOSTDO2)==F,]
#This selects the first Fix for each trial and each FixLoc, and codes all the useful information with it
tff.rs<-summaryBy(FixationStart ~ FixLoc+Participant + Trial + ItemF+ Named+Bias+Block+TargetOnset+TotDur+Age+BPVS+AGEYEAR, data=alr.D, FUN = min, keep.names=T, na.rm=T)

#Separately, we need to get Trial-specific information
trial.info<-summaryBy(DURPOSTDO2+DISCARDBONSET+DISCARDAONSET+DISCARDCONSET~Participant + Trial,data=alr.D, FUN = sum, keep.names=T, na.rm=T )

#merge the two files
tff.rs.m<-merge(tff.rs,trial.info,by=c("Participant","Trial"))

#now we need to apply the 40% rejection criterion
tff.rs.m$Perc_Dur<-tff.rs.m$DURPOSTDO2*100/(tff.rs.m$TotDur+1000-(tff.rs.m$TargetOnset+100))
tff.rs.m$DiscardTrial<-0
tff.rs.m$DiscardTrial[tff.rs.m$Perc_Dur<40]<-1
tff.rs.m$DiscardTrial[tff.rs.m$DiscardTrial>1]<-1
tff.rs.m<-tff.rs.m[tff.rs.m$DiscardTrial==0,]

#and discard fixations to the background (FixLoc == Background)
tff.rs.m<-tff.rs.m[tff.rs.m$FixLoc!="Background",]

#select only neutral trials
tff.rs.m.FLAT<-tff.rs.m[tff.rs.m$Bias=="FLAT",]

#and trials with looks to the Target at Onset+100
tff.rs.m.FLATB<-tff.rs.m.FLAT[tff.rs.m.FLAT$DISCARDBONSET==0&tff.rs.m.FLAT$Named=="B"&tff.rs.m.FLAT$FixLoc=="B",]
tff.rs.m.FLATA<-tff.rs.m.FLAT[tff.rs.m.FLAT$DISCARDAONSET==0&tff.rs.m.FLAT$Named=="A"&tff.rs.m.FLAT$FixLoc=="A",]
tff.rs.m.FLATC<-tff.rs.m.FLAT[tff.rs.m.FLAT$DISCARDCONSET==0&tff.rs.m.FLAT$Named=="C"&tff.rs.m.FLAT$FixLoc=="C",]

tff.rs.m.FLATABC<-rbind(tff.rs.m.FLATB,tff.rs.m.FLATA, tff.rs.m.FLATC)#1261 data points

# exclude cases in which target was not fixated before the end of the Recognition window (TotDurt+1000)
tff.rs.m.FLATABC<-tff.rs.m.FLATABC[tff.rs.m.FLATABC$FixationStart<tff.rs.m.FLATABC$TotDur+1000,] # no such cases

# get Fixation Onset relative to Target Noun Onset
tff.rs.m.FLATABC$FixStartRel<-tff.rs.m.FLATABC$FixationStart-tff.rs.m.FLATABC$TargetOnset

# now get by-participant averages, these will be the recognition speed index raw
tff.rs.m.FLATABC.bysubj<-summaryBy(FixStartRel~Participant+Age+BPVS,data=tff.rs.m.FLATABC,FUN=mean,keep.names = T)
# save to file
#write.table(tff.rs.m.FLATABC.bysubj,"raw_tff_recspeedindeces.txt",row.names = F)

```

### Analysis
```{r an proc_speed}
tff_raw<-read.table("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase1/raw_tff_recspeedindeces.txt",header=T)
names(tff_raw)[4]<-"tff_raw"
all<-merge(all,tff_model,by=c("Participant"),sort=F)
# Correlations
cor.test(all$tff_raw, all$Age) #-0.2965319, t = -4.5316, df = 213, p-value = 9.755e-06
cor.test(all$tff_raw, all$BPVS) #-0.2942354  , t = -4.4931, df = 213, p-value = 1.151e-05
## Model comparison
tff_rawR1<-lm(tff_raw~1+Age,data=all)
tff_rawR2<-lm(tff_raw~1+Age+scale(BPVS),data=all)
anova(tff_rawR1,tff_rawR2)
```

### Graph
```{r graph proc_speed}
#Figure 4C, main text
rec_raw_allc<-ggplot(all,aes(tff_raw,BPVS))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Size (raw BPVS score)")+xlab("Time to first fixation (Processing Speed)")
```

# Longitudinal Analyses {.tabset .tabset-fade}

## Setup
```{r setup long}
# This data file contains information on the longitudinal sample
data<-read.csv("https://raw.githubusercontent.com/chiara-gambi/gradedpred/master/phase2/longitudinal_part_info.csv",header=T)
# Note that it contains 56 rows, but eye-tracking data from one participant are missing, so in effect it is 55 participants
data55<-data[data$Eyetrack_data=="Y",]
# combine with the eye-tracking indeces
names(all)[4]<-"ParticipantNumber"
data.wi<-merge(data55,all,by=c("ParticipantNumber"))
# Note that there is one outlier with very large percentage linguistic change (>200)
# remove it now
data.wi<-data.wi[data.wi$LanCh<200,]
```

## Graph

```{r graph long}
# Figure 5, main text
# Panel A
pred_raw_all<-ggplot(data.wi,aes(PrecC_raw,LanCh))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Change (%)")+xlab("Graded Prediction Measure (Prediction Skill)")
# Panel B
predrev_raw_all<-ggplot(data.wi,aes(predrevR,LanCh))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Change (%)")+xlab("Predict-and-Redirect Measure (Revision Skill)")
# Panel C
rec_raw_all<-ggplot(data.wi,aes(tff_raw,LanCh))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Change (%)")+xlab("Time to first fixation (Processing Speed)")

# Combine the panels
pred_rec_predrev_raw_all<-ggarrange(pred_raw_all,predrev_raw_all,rec_raw_all,labels = c("A","B","C"), nrow=1)
ggsave("rec_pred_predrev_raw_all.png", plot=pred_rec_predrev_raw_all, width=45, height=15, unit="cm", dpi=300, path=getwd())

# Figure S6, Section 7, Supplement
# Panel A, preference
pred_raw_pref<-ggplot(data.wi,aes(rawPred,LanCh))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Change (%)")+xlab("Looks to Predictable - Mildly predictable pictures")
# Panel B, dispreference
pred_raw_dispref<-ggplot(data.wi,aes(rawUnpred,LanCh))+geom_point()+geom_smooth(method="lm",col="violet")+ylab("Vocabulary Change (%)")+xlab("Looks to Unpredictable - Mildly predictable pictures")
# combine the panels
pred_pred_dispref_raw_all<-ggarrange(pred_raw_pref,pred_raw_dispref,labels = c("A","B"), nrow=1)
ggsave("pred_pred_dispref_raw_all.png", plot=pred_pred_dispref_raw_all, width=45, height=15, unit="cm", dpi=300, path=getwd())

## Comparison of age and vocabulary distributions at Phase 1 across full sample and subsample (section 6, Supplement)
all$Sample<-all$retest
all$Sample<-factor(all$Sample,labels=c("Full sample (only)","Subsample"))
Age_comp<-ggplot(data=all, aes(x = Age, fill=Sample)) + geom_histogram(binwidth=0.5) + scale_fill_brewer(palette="RdYlBu")+ggtitle("Distribution of Age at Phase 1 for the full sample and the subsample")+xlab("Age in months")
ggsave("Age_comparison.png", plot=Age_comp, width=30, height=15, unit="cm", dpi=300, path=getwd())
Voc_comp<-ggplot(data=all, aes(x = BPVS, fill=Sample)) + geom_histogram(binwidth=1) + scale_fill_brewer(palette="RdYlBu")+ggtitle("Distribution of Vocabulary at Phase 1 for the full sample and the subsample")+xlab("BPVS raw score")
ggsave("Voc_comparison.png", plot=Voc_comp, width=30, height=15, unit="cm", dpi=300, path=getwd())
```


## Analyses
```{r long analyses}
# Controlling fro Vocabulary at Phase 1 (main text)

# Separate models predicting Vocabulary Growth
## Prediction skill (combined measure)
mVCp.raw.scale<-lm(LanCh~1+scale(PrecC_raw,T,T)+scale(RawBPVSScore1,T,F),data=data.wi)
summary(mVCp.raw.scale)
## Prediction skill (preference, section 7, Supplement)
mVCpp.raw.scale<-lm(LanCh~1+scale(rawPred,T,T)+scale(RawBPVSScore1,T,F),data=data.wi)
summary(mVCpp.raw.scale)
## Prediction skill (dispreference, Section 7, Supplement)
mVCpu.raw.scale<-lm(LanCh~1+scale(rawUnpred,T,T)+scale(RawBPVSScore1,T,F),data=data.wi)
summary(mVCpu.raw.scale)
## Revision skill
mVC.predrev.scale<-lm(LanCh~1+scale(predrevR,T,T)+scale(RawBPVSScore1,T,F),data=data.wi)
summary(mVC.predrev.scale)
## Processing speed
mVC.raw.scale<-lm(LanCh~1+scale(tff_raw,T,T)+scale(RawBPVSScore1, T, F),data=data.wi)
summary(mVC.raw.scale)
# Combined model: graded prediction skill and processing speed
mVC.pr<-lm(LanCh~1+scale(PrecC_raw,T,T)+scale(tff_raw,T,T)+scale(RawBPVSScore1,T,F),data=data.wi)
summary(mVC.pr)
# Combined score
data.wi$CPR<-scale(data.wi$PrecC_raw,T,T)-scale(data.wi$tff_raw,T,T)
mVC.pr.C<-lm(LanCh~1+scale(CPR,T,T)+scale(RawBPVSScore1,T,F),data=data.wi)
mVC.pr.baseline<-lm(LanCh~1+scale(RawBPVSScore1,T,F),data=data.wi)
summary(mVC.pr.C)
anova(mVC.pr.baseline,mVC.pr.C)


# Controlling for Age at Phase 1 (section 8, Supplement)
# Separate models predicting Vocabulary Change
## Prediction skill (combined measure)
mAp.raw.scale<-lm(LanCh~1+scale(PrecC_raw,T,T)+scale(Ageatfirsttest, T, F),data=data.wi)
summary(mAp.raw.scale)
## Revision skill
mA.predrev.scale<-lm(LanCh~1+scale(predrevR,T,T)+scale(Ageatfirsttest, T, F),data=data.wi)
summary(mA.predrev.scale)
## Processing speed
mA.raw.scale<-lm(LanCh~1+scale(tff_raw)+scale(Ageatfirsttest, T, F),data=data.wi)
summary(mA.raw.scale)
# Combined model: graded prediction skill and processing speed
mVC.pr.A<-lm(LanCh~1+scale(PrecC_raw,T,T)+scale(tff_raw,T,T)+scale(Ageatfirsttest,T,F),data=data.wi)
summary(mVC.pr.A)
# Combined score
mVC.pr.baseline.A<-lm(LanCh~1+scale(Ageatfirsttest,T,F),data=data.wi)
mVC.pr.C.A<-lm(LanCh~1+scale(CPR,T,T)+scale(Ageatfirsttest,T,F),data=data.wi)
summary(mVC.pr.C.A)
anova(mVC.pr.baseline.A,mVC.pr.C.A)

## Commonality analysis
library(yhat)
data.wi$scaleP<-scale(data.wi$PrecC_raw,T,T)
data.wi$scaleS<-scale(data.wi$tff_raw,T,T)
data.wi$centerV1<-scale(data.wi$RawBPVSScore1,T,F)
data.wisel<-data.wi[,c(10,60:62)]
commonalityCoefficients(data.wi,dv="LanCh", ivlist=list("scaleP","scaleS","centerV1"))
lm.out<-lm(LanCh~1+scaleP+scaleS+centerV1,data=data.wisel)
rg.out<-calc.yhat(lm.out)
rg.out


```

# Supplementary Analyses: Knowledge of Grammar and SES {.tabset .tabset-fade}

## Analayis
```{r an supp}
# Correlations
cor.test(data.wi$RawTROGScore2,data.wi$RawBPVSScore2) #0.7947496 , t = 9.4425, df = 52, p-value = 7.253e-13
cor.test(data.wi$RawTROGScore2,data.wi$Ageatsecondtest) #0.5314559, t = 4.5242, df = 52, p-value = 3.549e-05
cor.test(data.wi$RawTROGScore2,data.wi$PrecC_raw) # 0.2153655 , t = 1.5903, df = 52, p-value = 0.1178
cor.test(data.wi$RawTROGScore2,data.wi$predrevR) # 0.4165913 , t = 3.2403, df = 50, p-value = 0.002126
cor.test(data.wi$RawTROGScore2,data.wi$tff_raw) #-0.2055216, t = -1.5144, df = 52, p-value = 0.136

#multiple regression
mr.all2.grammar<-lm(RawTROGScore2~1+scale(Ageatsecondtest,T,F)+scale(RawBPVSScore2,T,F)+scale(PrecC_raw,T,T)+scale(tff_raw,T,T)+scale(predrevR,T,T),data=data.wi)
summary(mr.all2.grammar)
```

## Graph
```{r graph supp}
# Figure S1, Section 3, Supplement
graph2.raw<-data.wi[,-c(23:24,39:41)] #(remove Age and BPVS, and model-based Pred,Unpred and Speed to avoid duplicates)
names(graph2.raw)[43]<-"Speed"
names(graph2.raw)[47]<-"Rev"
names(graph2.raw)[49]<-"Pred"
names(graph2.raw)[8]<-"BPVS"
names(graph2.raw)[5]<-"Age"
names(graph2.raw)[18]<-"SES"
names(graph2.raw)[11]<-"TROG"
corr_test2.raw<-ggpairs(graph2.raw,columns=c("Pred","Rev","Speed","Age","BPVS","TROG","SES"), lower = list(continuous = my_fn))+theme(axis.text.x = element_text(size=5))
ggsave("corr_test2.raw.png", plot=corr_test2.raw, width=30, height=15, unit="cm", dpi=300, path=getwd())
```

